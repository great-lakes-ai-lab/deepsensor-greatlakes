{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "313e0a2b-f36f-468a-8d98-33ad8b99d830",
   "metadata": {},
   "source": [
    "# Import packages, define helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dc27116-7a2e-4252-a198-b9d52c636659",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import dask.array as da\n",
    "import gcsfs\n",
    "import os\n",
    "\n",
    "import deepsensor.torch\n",
    "from deepsensor.data import DataProcessor, TaskLoader, construct_circ_time_ds\n",
    "from deepsensor.data.sources import get_era5_reanalysis_data, get_earthenv_auxiliary_data, \\\n",
    "    get_gldas_land_mask\n",
    "from deepsensor.model import ConvNP\n",
    "from deepsensor.train import set_gpu_default_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e78cb96f-c4b9-4b1a-90a0-3fdb7db8b978",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def standardize_dates(ds):\n",
    "    \"\"\"\n",
    "    Convert the 'time' dimension in an xarray dataset to date-only precision with datetime64[D].\n",
    "    \n",
    "    Parameters:\n",
    "    ds (xarray.Dataset): The dataset whose 'time' dimension you wish to modify.\n",
    "    \n",
    "    Returns:\n",
    "    xarray.Dataset: Modified dataset with time as datetime64[D].\n",
    "    \"\"\"\n",
    "    if 'time' in ds.coords:\n",
    "        # Convert time to day-level precision\n",
    "        ds['time'] = ds['time'].dt.floor('D').values.astype('datetime64[D]')\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fd8e06-fc32-474a-abf4-f44f46ab21e9",
   "metadata": {},
   "source": [
    "# Data Inventory and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f1a2d3-2263-4076-9b92-a956ce383d70",
   "metadata": {},
   "source": [
    "### Temporal datasets: SST, ice concentration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44eb069e-cb9c-4811-a096-38254d982815",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Path to your Zarr stores\n",
    "ice_concentration_path = 'gs://great-lakes-osd/ice_concentration.zarr'\n",
    "glsea_path = 'gs://great-lakes-osd/GLSEA_combined.zarr'\n",
    "glsea3_path = 'gs://great-lakes-osd/GLSEA3_combined.zarr'\n",
    "\n",
    "# Open the Zarr stores\n",
    "ice_concentration_raw = xr.open_zarr(ice_concentration_path, chunks={'time': 366, 'lat': 200, 'lon': 200})\n",
    "glsea_raw = xr.open_zarr(glsea_path, chunks={'time': 366, 'lat': 200, 'lon': 200})\n",
    "glsea3_raw = xr.open_zarr(glsea3_path, chunks={'time': 366, 'lat': 200, 'lon': 200})\n",
    "\n",
    "# Replace -1 (land value) with NaN\n",
    "ice_concentration_raw = ice_concentration_raw.where(ice_concentration_raw != -1, float('nan'))\n",
    "\n",
    "# Convert all times to date-only format, removing the time component\n",
    "ice_concentration_raw = standardize_dates(ice_concentration_raw)\n",
    "glsea_raw = standardize_dates(glsea_raw)\n",
    "glsea3_raw = standardize_dates(glsea3_raw)\n",
    "\n",
    "# Drop CRS - not needed\n",
    "glsea_raw = glsea_raw.drop_vars('crs')\n",
    "glsea3_raw = glsea3_raw.drop_vars('crs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6663bb-aca3-4178-95a7-018fee440717",
   "metadata": {},
   "source": [
    "### Static datasets: lake mask, bathymetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "977c46d5-9ca6-4481-9531-e27c11b2ea1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up GCS filesystem\n",
    "fs = gcsfs.GCSFileSystem(project='your-gcp-project')\n",
    "\n",
    "# Path to the NetCDF files \n",
    "context_path = 'gs://great-lakes-osd/context/'\n",
    "\n",
    "# Open the NetCDF files using xarray with gcsfs\n",
    "bathymetry_raw = xr.open_dataset(fs.open(os.path.join(context_path, 'interpolated_bathymetry.nc')))\n",
    "lakemask_raw = xr.open_dataset(fs.open(os.path.join(context_path, 'lakemask.nc')))\n",
    "\n",
    "# Name the bathymetry variable\n",
    "bathymetry_raw = bathymetry_raw.rename({'__xarray_dataarray_variable__': 'bathymetry'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7979c0-a43f-4f8c-a177-058d5dfbce6c",
   "metadata": {},
   "source": [
    "# Data Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b90b872b-ed35-41d0-ab92-777fe052197c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataProcessor with normalisation params:\n",
      "{'coords': {'time': {'name': 'time'},\n",
      "            'x1': {'map': None, 'name': 'lat'},\n",
      "            'x2': {'map': None, 'name': 'lon'}}}\n"
     ]
    }
   ],
   "source": [
    "data_processor = DataProcessor(x1_name=\"lat\", x2_name=\"lon\")\n",
    "print(data_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a75be246-925b-4c49-8734-f92742fd14f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#glsea = data_processor(glsea_raw)\n",
    "_ = data_processor(glsea_raw.sel(time=slice(\"2009-01-01\", \"2009-12-31\")))\n",
    "glsea = data_processor(glsea_raw)\n",
    "\n",
    "# process the bathymetry and lake\n",
    "bathymetry, lakemask = data_processor([bathymetry_raw, lakemask_raw], method=\"min_max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9194ff8c-4caa-47cc-b704-600e1f738206",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (134,200,200) into shape (134,200)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m normalized_ice_concentration \u001b[38;5;241m=\u001b[39m ice_concentration_raw\u001b[38;5;241m.\u001b[39mmap_blocks(process_chunk, template\u001b[38;5;241m=\u001b[39mtemplate)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Compute the result (this will trigger the actual computation)\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m normalized_ice_concentration_computed \u001b[38;5;241m=\u001b[39m \u001b[43mnormalized_ice_concentration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Now `normalized_ice_concentration_computed` will hold the normalized data\u001b[39;00m\n",
      "File \u001b[0;32m~/deepsensor-greatlakes/venv/lib/python3.10/site-packages/xarray/core/dataset.py:714\u001b[0m, in \u001b[0;36mDataset.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Manually trigger loading and/or computation of this dataset's data\u001b[39;00m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;124;03mfrom disk or a remote source into memory and return a new dataset.\u001b[39;00m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;124;03mUnlike load, the original dataset is left unaltered.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;124;03mdask.compute\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    713\u001b[0m new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 714\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnew\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/deepsensor-greatlakes/venv/lib/python3.10/site-packages/xarray/core/dataset.py:541\u001b[0m, in \u001b[0;36mDataset.load\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m chunkmanager \u001b[38;5;241m=\u001b[39m get_chunked_array_type(\u001b[38;5;241m*\u001b[39mlazy_data\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m    540\u001b[0m \u001b[38;5;66;03m# evaluate all the chunked arrays simultaneously\u001b[39;00m\n\u001b[0;32m--> 541\u001b[0m evaluated_data: \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray[Any, Any], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mchunkmanager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlazy_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(lazy_data, evaluated_data, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    546\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables[k]\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m~/deepsensor-greatlakes/venv/lib/python3.10/site-packages/xarray/namedarray/daskmanager.py:85\u001b[0m, in \u001b[0;36mDaskManager.compute\u001b[0;34m(self, *data, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute\u001b[39m(\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mdata: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m     82\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray[Any, _DType_co], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]:\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compute\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/deepsensor-greatlakes/venv/lib/python3.10/site-packages/dask/base.py:681\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    678\u001b[0m     expr \u001b[38;5;241m=\u001b[39m expr\u001b[38;5;241m.\u001b[39moptimize()\n\u001b[1;32m    679\u001b[0m     keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(flatten(expr\u001b[38;5;241m.\u001b[39m__dask_keys__()))\n\u001b[0;32m--> 681\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack(results)\n",
      "File \u001b[0;32m~/deepsensor-greatlakes/venv/lib/python3.10/site-packages/dask/array/core.py:5483\u001b[0m, in \u001b[0;36mconcatenate3\u001b[0;34m(arrays)\u001b[0m\n\u001b[1;32m   5481\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m<\u001b[39m ndim:\n\u001b[1;32m   5482\u001b[0m             arr \u001b[38;5;241m=\u001b[39m arr[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[0;32m-> 5483\u001b[0m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr\n\u001b[1;32m   5485\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (134,200,200) into shape (134,200)"
     ]
    }
   ],
   "source": [
    "# Select a subset of the ice concentration data to compute normalization parameters\n",
    "_ = data_processor(ice_concentration_raw.sel(time=slice(\"2009-01-01\", \"2009-01-31\")))\n",
    "\n",
    "# Now apply the normalization parameters to the full ice concentration dataset\n",
    "#ice_concentration = data_processor(ice_concentration_raw, method=\"min_max\")\n",
    "\n",
    "import dask.array as da\n",
    "\n",
    "# Open the Zarr file with dask chunks\n",
    "ice_concentration_raw = xr.open_zarr(ice_concentration_path, chunks={'time': 366, 'lat': 200, 'lon': 200})\n",
    "\n",
    "def process_chunk(chunk):\n",
    "    # Calculate min and max for the chunk\n",
    "    min_value = chunk.min()\n",
    "    max_value = chunk.max()\n",
    "    \n",
    "    # Check if the min and max are the same (no variation)\n",
    "    if min_value == max_value:\n",
    "        return chunk  # or set it to a constant value, if needed\n",
    "    \n",
    "    # Otherwise, apply normalization using the DataProcessor\n",
    "    return data_processor(chunk, method=\"min_max\")\n",
    "\n",
    "# Provide a template to map_blocks\n",
    "template = ice_concentration_raw.isel(time=0)  # Take a single slice (e.g., the first time step) to use as the template\n",
    "\n",
    "# Process the chunks of the ice concentration data lazily using Dask\n",
    "normalized_ice_concentration = ice_concentration_raw.map_blocks(process_chunk, template=template)\n",
    "\n",
    "# Compute the result (this will trigger the actual computation)\n",
    "normalized_ice_concentration_computed = normalized_ice_concentration.compute()\n",
    "\n",
    "# Now `normalized_ice_concentration_computed` will hold the normalized data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a9c77af-3acd-4142-97af-c42375188ebd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 8MB\n",
      "Dimensions:            (lat: 1024, lon: 1024)\n",
      "Coordinates:\n",
      "  * lat                (lat) float64 8kB 50.6 50.59 50.58 ... 38.9 38.89 38.87\n",
      "  * lon                (lon) float64 8kB -92.41 -92.39 -92.38 ... -75.89 -75.87\n",
      "    time               datetime64[ns] 8B 1972-12-01\n",
      "Data variables:\n",
      "    ice_concentration  (lat, lon) float64 8MB dask.array<chunksize=(200, 200), meta=np.ndarray>\n",
      "Attributes: (12/23)\n",
      "    coverage_area:            Great Lakes\n",
      "    data_source:              NOAA\n",
      "    description:              Great Lakes ice concentrations\n",
      "    disclaimer:               Data collected and processed by NOAA and dissem...\n",
      "    dissemination:            USNIC Website, CIS Website\n",
      "    grid_resolution:          1.800 km\n",
      "    ...                       ...\n",
      "    product:                  GRID - Resolution 1800\n",
      "    source:                   NAIS daily Great Lakes ice analysis\n",
      "    source_url:               https://noaadata.apps.nsidc.org/NOAA/G10029/\n",
      "    spatial_extent:           Lat: 38.87N to 50.6N, Lon: 92.41W to 75.87W\n",
      "    time_range:               2009-01-01 to 2009-12-31\n",
      "    units:                    Ice concentration (%)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'min'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m Q \u001b[38;5;241m=\u001b[39m ice_concentration_raw\u001b[38;5;241m.\u001b[39misel(time\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m()\u001b[38;5;241m.\u001b[39mvalue\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'min'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415e8429-6c23-472d-b119-f336dd3d01ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_processor.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee20682-a5f3-4196-b06d-db17277ac04c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dates = pd.date_range(glsea.time.values.min(), glsea.time.values.max(), freq=\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f11be2-b77e-4444-ba92-1563b29adf18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doy_ds = construct_circ_time_ds(dates, freq=\"D\")\n",
    "cosD = standardize_dates(doy_ds[\"cos_D\"])\n",
    "sinD = standardize_dates(doy_ds[\"sin_D\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7b4067-ff24-4721-8c59-831ada6eca4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sinD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28865dcf-db11-4839-bb43-a0e46dc418be",
   "metadata": {},
   "source": [
    "# Sanity checks after being run through the data_processor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba2e426-e044-400c-a851-173f64163f59",
   "metadata": {},
   "source": [
    "### Sanity check: ice concentration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ef7aca-7f8f-47a2-ba5c-7cc8b041707a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ice_concentration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b38644-1f65-4675-95a0-4db99338d1a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "ds = ice_concentration\n",
    "\n",
    "# Select a single time slice to plot, e.g., the first time point\n",
    "time_index = 20\n",
    "time_slice = ds.isel(time=time_index)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "ice_conc_plot = time_slice.ice_concentration.plot(\n",
    "    x='x2', \n",
    "    y='x1', \n",
    "    cmap='Blues',\n",
    "    robust=True  # Automatically exclude extreme outliers from color scaling\n",
    ")\n",
    "plt.title(f\"Ice Concentration on {str(time_slice.time.values)}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb944c30-22aa-4139-a564-96def79993d7",
   "metadata": {},
   "source": [
    "### Sanity check: GLSEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9669b243-c4bc-4f99-9247-b2ba15459215",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "glsea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7490a5a-3b8c-4945-ba5d-7e1a282c2eb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "ds = glsea\n",
    "\n",
    "# Select a single time slice to plot, e.g., the first time point\n",
    "time_index = 20\n",
    "time_slice = ds.isel(time=time_index)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "ice_conc_plot = time_slice.sst.plot(\n",
    "    x='x2', \n",
    "    y='x1', \n",
    "    cmap='cividis',\n",
    "    robust=True  # Automatically exclude extreme outliers from color scaling\n",
    ")\n",
    "plt.title(f\"GLSEA on {str(time_slice.time.values)}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4525d50e-9b43-4a62-b89a-0b6e270e828f",
   "metadata": {},
   "source": [
    "### Sanity check: bathymetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3fbb19-2624-4578-83ab-38876d09b743",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bathymetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6006b2-1cc1-4e4e-bee2-a5a038451077",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "ds = bathymetry\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "ice_conc_plot = ds.bathymetry.plot(\n",
    "    x='x2', \n",
    "    y='x1', \n",
    "    cmap='cividis',\n",
    "    robust=True  # Automatically exclude extreme outliers from color scaling\n",
    ")\n",
    "plt.title(f\"GLSEA on {str(time_slice.time.values)}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee938157-5331-4b7e-b673-0e004687fa7e",
   "metadata": {},
   "source": [
    "### Sanity check: lake mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079e72f5-4f98-4244-8072-d34a4905b53a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakemask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe381c27-9363-4644-8a2e-abd69e8bda95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot lakemask\n",
    "lakemask_mask = lakemask['mask']\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 8))\n",
    "lakemask_mask.plot(cmap='Blues', add_colorbar=True)\n",
    "plt.title('Mask from lakemask.nc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5cf13d-7adb-41df-b5eb-ba2395de1d29",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38acbd3-de41-445d-a120-ed86dda5252a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generating random coordinates from inside the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d91a53-e891-4464-a702-649de0cfc7e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_random_coordinates(mask_da, N, data_processor=None):\n",
    "    \"\"\"\n",
    "    Generate N random coordinates (lat, lon) from a mask with values 1 inside the lake area,\n",
    "    and normalize them using the DataProcessor if provided.\n",
    "    \n",
    "    Parameters:\n",
    "    mask_da: xarray DataArray containing the mask (with 1 for valid, 0 for invalid areas)\n",
    "    N: Number of random points to generate\n",
    "    data_processor: (optional) DataProcessor object for normalization if needed\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: Array of shape (2, N) with random latitudes and longitudes from the masked region\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the valid indices where the mask is 1\n",
    "    mask = mask_da['mask'].values\n",
    "    valid_indices = np.argwhere(mask == 1)\n",
    "    \n",
    "    # Randomly sample N points from the valid indices\n",
    "    random_indices = valid_indices[np.random.choice(valid_indices.shape[0], N, replace=False)]\n",
    "    \n",
    "    # Get the latitude and longitude coordinates for the sampled indices\n",
    "    latitudes = mask_da['lat'].values[random_indices[:, 0]]\n",
    "    longitudes = mask_da['lon'].values[random_indices[:, 1]]\n",
    "    \n",
    "    # Create a dummy variable (e.g., zeros for now)\n",
    "    dummy_variable = np.random.rand(N)\n",
    "    \n",
    "    # Create a Pandas DataFrame with latitudes, longitudes, and the dummy variable\n",
    "    random_coords_df = pd.DataFrame({\n",
    "        'lat': latitudes,\n",
    "        'lon': longitudes,\n",
    "        'dummy': dummy_variable\n",
    "    })\n",
    "    \n",
    "    # Set the index to ['lat', 'lon'] to match what DataProcessor expects\n",
    "    random_coords_df = random_coords_df.set_index(['lat', 'lon'])\n",
    "    \n",
    "    if data_processor:\n",
    "        normalized_coords_df = data_processor(random_coords_df, method=\"min_max\")\n",
    "        return normalized_coords_df.index.to_frame(index=False).values.T\n",
    "    else:\n",
    "        return np.vstack((latitudes, longitudes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe8789c-a205-4d66-a597-ed123cdeb38c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "N = 100  # Number of random points\n",
    "random_lake_points = generate_random_coordinates(lakemask_raw, N, data_processor)\n",
    "random_lake_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cc0577-5a36-45f4-b4e8-2a849b90f47a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming random_coords is the (2, N) array from the previous step\n",
    "latitudes = random_lake_points[0, :]\n",
    "longitudes = random_lake_points[1, :]\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(longitudes, latitudes, color='blue', alpha=0.5, s=10)\n",
    "plt.title(\"Scatter plot of N Random Coordinates within Lake Mask\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182c1497-16fe-49eb-8a29-494e4b7ff7cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from deepsensor.data import TaskLoader\n",
    "task_loader = TaskLoader(context=[glsea, ice_concentration, bathymetry, lakemask], target=glsea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a1c2b7-bce1-43eb-83cf-70b103d4cd47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task_loader.context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b008f63a-9805-4985-b826-2f7db680e64e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task = task_loader(\"2011-08-16T00:00:00\", context_sampling=random_lake_points, target_sampling=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f819c46-8bb0-4658-b82d-df092f31b868",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9de15b-08da-4c23-9762-def4876984ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = deepsensor.plot.task(task, task_loader)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914433dd-c915-4ab6-88f9-6db21f82eaaa",
   "metadata": {},
   "source": [
    "## Attempt task with points sampled from lakes only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6850f1f7-a26e-495a-9f43-dbeefebf9024",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task = task_loader(\"2011-08-16T00:00:00\", context_sampling=random_lake_points, target_sampling=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5004fc-4458-4cfa-b992-07fc350e4acc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ec282b-3140-419f-be93-b46c17d230f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = deepsensor.plot.task(task, task_loader)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6f5067-71c5-4fa1-98ef-e9e443afc43c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "venv",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python (deepsensor_env_gpu) (Local)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
